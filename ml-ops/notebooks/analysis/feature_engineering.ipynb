{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline\n",
    "\n",
    "This notebook implements the feature engineering pipeline for the telecom data analysis project. We'll create features from:\n",
    "1. Network Performance Data\n",
    "2. Customer Experience Data\n",
    "3. Call Detail Records\n",
    "\n",
    "These features will be used for training machine learning models to predict network issues and customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "network_df = pd.read_csv(\"../../data/raw/sample_data/network_performance_sample.csv\")\n",
    "customer_df = pd.read_csv(\"../../data/raw/sample_data/customer_experience_sample.csv\")\n",
    "cdr_df = pd.read_csv(\"../../data/raw/sample_data/call_detail_records_sample.csv\")\n",
    "\n",
    "# Convert timestamps to datetime\n",
    "network_df[\"timestamp\"] = pd.to_datetime(network_df[\"timestamp\"])\n",
    "customer_df[\"timestamp\"] = pd.to_datetime(customer_df[\"timestamp\"])\n",
    "cdr_df[\"timestamp\"] = pd.to_datetime(cdr_df[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "### 2.1 Time-based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features from timestamps\n",
    "def add_time_features(df, timestamp_col='timestamp'):\n",
    "    df = df.copy()\n",
    "    df['hour'] = df[timestamp_col].dt.hour\n",
    "    df['day_of_week'] = df[timestamp_col].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['is_peak_hour'] = df['hour'].between(9, 17).astype(int)\n",
    "    return df\n",
    "\n",
    "# Apply time features to all datasets\n",
    "network_df = add_time_features(network_df)\n",
    "customer_df = add_time_features(customer_df)\n",
    "cdr_df = add_time_features(cdr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Network Performance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling statistics for network performance metrics\n",
    "def add_network_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Group by cell_id and calculate rolling statistics\n",
    "    grouped = df.groupby('cell_id')\n",
    "    \n",
    "    # Calculate rolling means for key metrics\n",
    "    df['rolling_latency'] = grouped['latency_ms'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "    df['rolling_packet_loss'] = grouped['packet_loss'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "    df['rolling_throughput'] = grouped['throughput_mbps'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "    \n",
    "    # Calculate performance degradation indicators\n",
    "    df['latency_increase'] = df['latency_ms'] > df['rolling_latency']\n",
    "    df['packet_loss_increase'] = df['packet_loss'] > df['rolling_packet_loss']\n",
    "    df['throughput_decrease'] = df['throughput_mbps'] < df['rolling_throughput']\n",
    "    \n",
    "    return df\n",
    "\n",
    "network_df = add_network_features(network_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Customer Experience Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate customer behavior patterns\n",
    "def add_customer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Group by customer_id and calculate statistics\n",
    "    grouped = df.groupby('customer_id')\n",
    "    \n",
    "    # Calculate usage patterns\n",
    "    df['avg_data_usage'] = grouped['data_usage_mb'].transform('mean')\n",
    "    df['avg_voice_minutes'] = grouped['voice_minutes'].transform('mean')\n",
    "    df['avg_sms_count'] = grouped['sms_count'].transform('mean')\n",
    "    \n",
    "    # Calculate satisfaction trends\n",
    "    df['satisfaction_trend'] = grouped['customer_satisfaction_score'].transform(\n",
    "        lambda x: x.diff().fillna(0)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "customer_df = add_customer_features(customer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Call Detail Record Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate call quality and usage patterns\n",
    "def add_cdr_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Group by caller_id and calculate statistics\n",
    "    grouped = df.groupby('caller_id')\n",
    "    \n",
    "    # Calculate call patterns\n",
    "    df['avg_call_duration'] = grouped['call_duration_seconds'].transform('mean')\n",
    "    df['total_data_used'] = grouped['data_used_mb'].transform('sum')\n",
    "    \n",
    "    # Calculate call quality indicators\n",
    "    df['is_long_call'] = df['call_duration_seconds'] > df['avg_call_duration']\n",
    "    df['is_high_data_usage'] = df['data_used_mb'] > df['total_data_used']\n",
    "    \n",
    "    return df\n",
    "\n",
    "cdr_df = add_cdr_features(cdr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Cross-dataset Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature set shape: (6, 50)\n",
      "\n",
      "Feature columns:\n",
      "['customer_id', 'timestamp', 'service_type', 'data_usage_mb', 'voice_minutes', 'sms_count', 'network_quality_score', 'customer_satisfaction_score', 'hour_x', 'day_of_week_x', 'is_weekend_x', 'is_peak_hour_x', 'avg_data_usage', 'avg_voice_minutes', 'avg_sms_count', 'satisfaction_trend', 'cell_id_x', 'latency_ms', 'packet_loss', 'throughput_mbps', 'signal_strength', 'connection_type', 'hour_y', 'day_of_week_y', 'is_weekend_y', 'is_peak_hour_y', 'rolling_latency', 'rolling_packet_loss', 'rolling_throughput', 'latency_increase', 'packet_loss_increase', 'throughput_decrease', 'call_id', 'caller_id', 'callee_id', 'call_duration_seconds', 'call_type', 'cell_id_y', 'roaming_status', 'data_used_mb', 'hour', 'day_of_week', 'is_weekend', 'is_peak_hour', 'avg_call_duration', 'total_data_used', 'is_long_call', 'is_high_data_usage', 'network_quality_impact', 'customer_experience_score']\n"
     ]
    }
   ],
   "source": [
    "# Combine features from different datasets\n",
    "def create_cross_dataset_features(network_df, customer_df, cdr_df):\n",
    "    # Merge network and customer data based on timestamp\n",
    "    merged_df = pd.merge_asof(\n",
    "        customer_df.sort_values('timestamp'),\n",
    "        network_df.sort_values('timestamp'),\n",
    "        on='timestamp',\n",
    "        direction='nearest'\n",
    "    )\n",
    "    \n",
    "    # Add CDR data\n",
    "    merged_df = pd.merge_asof(\n",
    "        merged_df.sort_values('timestamp'),\n",
    "        cdr_df.sort_values('timestamp'),\n",
    "        on='timestamp',\n",
    "        direction='nearest'\n",
    "    )\n",
    "    \n",
    "    # Calculate cross-dataset features\n",
    "    merged_df['network_quality_impact'] = (\n",
    "        merged_df['latency_ms'] * merged_df['packet_loss'] / merged_df['throughput_mbps']\n",
    "    )\n",
    "    \n",
    "    merged_df['customer_experience_score'] = (\n",
    "        merged_df['customer_satisfaction_score'] * (1 - merged_df['network_quality_impact'])\n",
    "    )\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Create the final feature set\n",
    "final_features = create_cross_dataset_features(network_df, customer_df, cdr_df)\n",
    "\n",
    "# Display the final feature set\n",
    "print(\"Final feature set shape:\", final_features.shape)\n",
    "print(\"\\nFeature columns:\")\n",
    "print(final_features.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
